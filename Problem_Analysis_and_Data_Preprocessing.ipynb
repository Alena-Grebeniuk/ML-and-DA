{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WhpMgiS1o5A"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The goal of this lab is to introduce you to data preprocessing techniques in order to make your data suitable for applying a learning algorithm.\n",
        "\n",
        "## 1. Handling Missing Values\n",
        "\n",
        "A common (and very unfortunate) data property is the ocurrence of missing and erroneous values in multiple features in datasets. For this exercise we will be using a data set about abalone snails.\n",
        "The data set is contained in the Zip file you downloaded from Moodle (abalone.csv).\n",
        "\n",
        "To determine the age of a abalone snail you have to kill the snail and count the annual\n",
        "rings. You are told to estimate the age of a snail on the basis of the following attributes:\n",
        "1. type: male (0), female (1) and infant (2)\n",
        "2. length in mm\n",
        "3. width in mm\n",
        "4. height in mm\n",
        "5. total weight in grams\n",
        "6. weight of the meat in grams\n",
        "7. drained weight in grams\n",
        "8. weight of the shell in grams\n",
        "9. number of annual rings (number of rings +1, 5 yields age)\n",
        "\n",
        "However, the data is incomplete. Missing values are marked with −1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEuTCY-cIJU2",
        "outputId": "ce829ae8-44df-4f76-c0c6-f9306f63b295"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aTRoZnye1o5D",
        "outputId": "609e2669-5653-4870-e248-9f5562f7c2b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   type  length  width  height  total_weight  meat_weight  drained_weight  \\\n",
              "0     0   0.350  0.265   0.090        0.2255       0.0995          0.0485   \n",
              "1     1   0.530  0.420   0.135        0.6770       0.2565          0.1415   \n",
              "2     0   0.440  0.365   0.125        0.5160       0.2155          0.1140   \n",
              "3     2  -1.000  0.255   0.080        0.2050       0.0895          0.0395   \n",
              "4     2   0.425  0.300   0.095        0.3515       0.1410          0.0775   \n",
              "\n",
              "   shell_weight  num_rings  \n",
              "0         0.070         -1  \n",
              "1         0.210          9  \n",
              "2         0.155         10  \n",
              "3         0.055          7  \n",
              "4         0.120          8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5de61a76-606d-4feb-9e78-ed90456be9a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>length</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>total_weight</th>\n",
              "      <th>meat_weight</th>\n",
              "      <th>drained_weight</th>\n",
              "      <th>shell_weight</th>\n",
              "      <th>num_rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.070</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.210</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.155</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.000</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.055</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.3515</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.120</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5de61a76-606d-4feb-9e78-ed90456be9a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5de61a76-606d-4feb-9e78-ed90456be9a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5de61a76-606d-4feb-9e78-ed90456be9a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1aa9f6d9-0398-4600-b8f9-42e475c7cf0b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1aa9f6d9-0398-4600-b8f9-42e475c7cf0b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1aa9f6d9-0398-4600-b8f9-42e475c7cf0b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4176,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 2,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.284509219124946,\n        \"min\": -1.0,\n        \"max\": 0.815,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          0.675,\n          0.17,\n          0.395\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2582582003019584,\n        \"min\": -1.0,\n        \"max\": 0.65,\n        \"num_unique_values\": 112,\n        \"samples\": [\n          0.325,\n          0.46,\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19777851105737043,\n        \"min\": -1.0,\n        \"max\": 1.13,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          0.045,\n          0.225,\n          0.015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5625429769346814,\n        \"min\": -1.0,\n        \"max\": 2.8255,\n        \"num_unique_values\": 2397,\n        \"samples\": [\n          0.8075,\n          0.6345,\n          0.6875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"meat_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31894838785693375,\n        \"min\": -1.0,\n        \"max\": 1.488,\n        \"num_unique_values\": 1504,\n        \"samples\": [\n          0.192,\n          0.129,\n          0.432\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drained_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2169310865445354,\n        \"min\": -1.0,\n        \"max\": 0.76,\n        \"num_unique_values\": 874,\n        \"samples\": [\n          0.088,\n          0.0905,\n          0.1005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shell_weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23547771154771446,\n        \"min\": -1.0,\n        \"max\": 1.005,\n        \"num_unique_values\": 919,\n        \"samples\": [\n          0.41,\n          0.385,\n          0.1785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_rings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": -1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          25,\n          6,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# load data\n",
        "df = pd.read_csv(\"http://www.cs.uni-potsdam.de/ml/teaching/ss15/ida/uebung02/abalone.csv\") #Should this not work please use the csv that was part of the zip file.\n",
        "df.columns=['type','length','width','height','total_weight','meat_weight','drained_weight','shell_weight','num_rings']\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_KMa47j1o5E"
      },
      "source": [
        "### Exercise 1.1\n",
        "\n",
        "Compute the mean of of each numeric column and the counts of each categorical column, excluding the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-dCq2-NW1o5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77658414-f378-43c4-c1ce-3327dd77d6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means of numeric columns:\n",
            "length            0.478448\n",
            "width             0.366148\n",
            "height            0.105771\n",
            "total_weight      0.782421\n",
            "meat_weight       0.318576\n",
            "drained_weight    0.149442\n",
            "shell_weight      0.208351\n",
            "num_rings         9.662835\n",
            "dtype: float64\n",
            "\n",
            "Counts of each category in 'type':\n",
            "type\n",
            " 0    1500\n",
            " 2    1310\n",
            " 1    1279\n",
            "-1      87\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# import pandas as pd was already included at the top of your script\n",
        "\n",
        "# Assuming df has been loaded with abalone data as per your script\n",
        "\n",
        "# Compute the mean for numeric columns excluding missing values\n",
        "numeric_columns = ['length', 'width', 'height', 'total_weight', 'meat_weight', 'drained_weight', 'shell_weight', 'num_rings']\n",
        "means = df[numeric_columns].mean()  # This excludes NaN values by default\n",
        "\n",
        "# Compute the counts for the categorical column, again excluding missing values\n",
        "# If 'type' is indeed the categorical column:\n",
        "categorical_counts = df['type'].value_counts()  # This also excludes NaN by default\n",
        "\n",
        "# Display the results\n",
        "print(\"Means of numeric columns:\")\n",
        "print(means)\n",
        "print(\"\\nCounts of each category in 'type':\")\n",
        "print(categorical_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I0CjV2c1o5G"
      },
      "source": [
        "### Exercise 1.2\n",
        "\n",
        "Compute the median of each numeric column,  excluding the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sw_28SAt1o5G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb577d3-0345-4f12-b238-5e254cab4d57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median of each numeric column:\n",
            "type              1.000\n",
            "length            0.535\n",
            "width             0.420\n",
            "height            0.140\n",
            "total_weight      0.782\n",
            "meat_weight       0.327\n",
            "drained_weight    0.166\n",
            "shell_weight      0.225\n",
            "num_rings         9.000\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Assuming df is your DataFrame\n",
        "# Compute the median for numeric columns\n",
        "median_values = df.median()\n",
        "\n",
        "print(\"Median of each numeric column:\")\n",
        "print(median_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMltOlp_1o5G"
      },
      "source": [
        "### Exercise 1.3\n",
        "\n",
        "Handle the missing values in a way that you find suitable. Think about different ways. Discuss dis-/advantages of your approach. Argue your choices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.3 involves handling missing values in a dataset. The right approach to handle missing values significantly depends on the nature of your data, the proportion of missing values, and the intended analysis or model building. Here are several common strategies to deal with missing values in Python using pandas, along with their advantages and disadvantages.\n",
        "\n",
        "# 1. Removing Rows with Missing Values"
      ],
      "metadata": {
        "id": "0NgL28YSVpVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxDCHrb31o5G"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_cleaned = df.dropna()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "\n",
        "- Simple and easy to implement.\n",
        "\n",
        "- Can help improve model accuracy when the reason for missingness isn't related to the data itself.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Potential loss of a lot of data, especially if the dataset is small or missing values are widespread.\n",
        "\n",
        "- Can introduce bias if the missing data is not randomly distributed.\n",
        "\n",
        "# 2. Filling Missing Values with a Constant or a Summary Statistic"
      ],
      "metadata": {
        "id": "RRwk-PpFV45h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filling with a constant\n",
        "df_filled_constant = df.fillna(0)\n",
        "\n",
        "# Filling with mean of the column\n",
        "df_filled_mean = df.fillna(df.mean())"
      ],
      "metadata": {
        "id": "dSMZcszHV7Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "\n",
        "- Preserves the dataset size, allowing for more extensive data analysis.\n",
        "\n",
        "- Easy to implement and can be customized based on the domain knowledge (e.g., filling age with the median).\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Can introduce bias, especially if the missingness is systematic.\n",
        "\n",
        "- Filling with a constant like 0 might not always make sense and can skew the data distribution.\n",
        "\n",
        "# 3. Predicting Missing Values"
      ],
      "metadata": {
        "id": "stIvrh4ZV9UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is more complex and requires using models to predict the missing\n",
        "# values based on other variables."
      ],
      "metadata": {
        "id": "qEGcSx_jWBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Advantages:\n",
        "\n",
        "- Can be very accurate if the model is well-tuned and the data variables are highly correlated.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Complex and time-consuming to implement.\n",
        "\n",
        "- Risk of overfitting the model to the data.\n",
        "\n",
        "4. Using Algorithms that Support Missing Values\n",
        "Some machine learning algorithms, such as XGBoost, can handle missing values internally.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "- No need to preprocess the missing values, which streamlines the modeling process.\n",
        "\n",
        "- The algorithm may find an optimal way to handle missingness.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "- Limited to the algorithms that have this feature.\n",
        "\n"
      ],
      "metadata": {
        "id": "ynLoAIxUWFYf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpklBouL1o5H"
      },
      "source": [
        "### Exercise 1.4\n",
        "\n",
        "Perform Z-score normalization on every column (except the type of course!)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Exercise 1.4, assuming you wish to perform Z-score normalization on a dataset where every column except one (labelled, for instance, \"type_of_course\") should be normalized. Z-score normalization (also known as Standard Score or Standardization) involves transforming data into a common scale with a mean of 0 and a standard deviation of 1.\n",
        "\n",
        "In Python, we can use the pandas library for handling the dataset and the Scipy library or sklearn.preprocessing for performing the standardization."
      ],
      "metadata": {
        "id": "hmGq6_-UX3l-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HbkY--hk1o5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d22e6a-315f-44c8-f987-6c8db44ee399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   type    length     width    height  total_weight  meat_weight  \\\n",
            "0     0 -0.451473 -0.391655 -0.079741     -0.990006    -0.686869   \n",
            "1     1  0.181195  0.208519  0.147786     -0.187401    -0.194627   \n",
            "2     0 -0.135139 -0.004446  0.097225     -0.473601    -0.323174   \n",
            "3     2 -5.196486 -0.430376 -0.130303     -1.026448    -0.718223   \n",
            "4     2 -0.187861 -0.256132 -0.054460     -0.766023    -0.556754   \n",
            "\n",
            "   drained_weight  shell_weight  num_rings  \n",
            "0       -0.465320     -0.587534  -2.965209  \n",
            "1       -0.036612      0.007002  -0.184327  \n",
            "2       -0.163380     -0.226566   0.093762  \n",
            "3       -0.506807     -0.651234  -0.740503  \n",
            "4       -0.331637     -0.375200  -0.462415  \n"
          ]
        }
      ],
      "source": [
        "# Now, perform Z-score normalization on every column except 'type'\n",
        "# Excluding 'type' from normalization\n",
        "features = df.columns[1:]  # This selects all columns except the first one which is 'type'\n",
        "\n",
        "# Apply Z-score normalization\n",
        "for feature in features:\n",
        "    df[feature] = (df[feature] - df[feature].mean()) / df[feature].std()\n",
        "\n",
        "# Display the first few rows after normalization\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krOpdi_i1o5J"
      },
      "source": [
        "## 2. Preprocessing text (Optional)\n",
        "\n",
        "One possible way to transform text documents into vectors of numeric attributes is to use the TF-IDF representation. We will experiment with this representation using the 20 Newsgroup data set. The data set contains postings on 20 different topics. The classification problem is to decide which of the topics a posting falls into. Here, we will only consider postings about medicine and space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TmhZ8_FC1o5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89a2ec7-4675-4c71-d0ac-bd5940b60c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The index of each category is: [(0, 'sci.med'), (1, 'sci.space')]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "\n",
        "categories = ['sci.med', 'sci.space']\n",
        "raw_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "print(f'The index of each category is: {[(i,target) for i,target in enumerate(raw_data.target_names)]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kWdpZz61o5K"
      },
      "source": [
        "Check out some of the postings, might find some funny ones!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CFZgvye31o5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "accd5df4-30ed-4cf0-bbef-fc669934a317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a sci.med email.\n",
            "\n",
            "There are 1187 emails.\n",
            "\n",
            "Organization: University of Illinois at Chicago, academic Computer Center\n",
            "From: <U19250@uicvm.uic.edu>\n",
            "Subject: quality control in medicine\n",
            "Lines: 7\n",
            "\n",
            "Does anybody know of any information regarding the implementaion of total\n",
            " quality management, quality control, quality assurance in the delivery of\n",
            " health care service.  I would appreciate any information.  If there is enough\n",
            "interest, I will post the responses.\n",
            "        Thank You\n",
            "        Abhin Singla MS BioE, MBA, MD\n",
            "        President AC Medcomp Inc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "idx = np.random.randint(0, len(raw_data.data))\n",
        "print (f'This is a {raw_data.target_names[raw_data.target[idx]]} email.\\n')\n",
        "print (f'There are {len(raw_data.data)} emails.\\n')\n",
        "print(raw_data.data[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytNRgBtD1o5L"
      },
      "source": [
        "Lets pick the first 10 postings from each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7XjYd0ML1o5L"
      },
      "outputs": [],
      "source": [
        "idxs_med = np.flatnonzero(raw_data.target == 0)\n",
        "idxs_space = np.flatnonzero(raw_data.target == 1)\n",
        "idxs = np.concatenate([idxs_med[:10],idxs_space[:10]])\n",
        "data = np.array(raw_data.data)\n",
        "data = data[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY4YffVy1o5M"
      },
      "source": [
        "<a href=\"http://www.nltk.org/\">NLTK</a> is a toolkit for natural language processing. Take some time to install it and go through this <a href=\"http://www.slideshare.net/japerk/nltk-in-20-minutes\">short tutorial/presentation</a>. (or use e.g. Google colab where the package is prepared already)\n",
        "\n",
        "The downloaded package below is a tokenizer that divides a text into a list of sentences, by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GhpnijnB1o5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7ad1c6-6377-486b-bdca-f733089cc917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import itertools\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Tokenize the sentences into words\n",
        "tokenized_sentences = [nltk.word_tokenize(sent) for sent in data]\n",
        "vocabulary_size = 1000\n",
        "unknown_token = 'unknown'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LvKCOBjx1o5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a49d41b-a001-4177-c09f-c506ef3eaeae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1636 unique words tokens.\n"
          ]
        }
      ],
      "source": [
        "# Count the word frequencies\n",
        "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
        "print (f\"Found {len(word_freq.items())} unique words tokens.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yw_h_8Vo1o5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f11c60d-3aff-435d-ea5f-dc1d35a05bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using vocabulary size 1000.\n",
            "The least frequent word in our vocabulary is 'AN' and appeared 1 times.\n"
          ]
        }
      ],
      "source": [
        "# Get the most common words and build index_to_word and word_to_index vectors\n",
        "vocab = word_freq.most_common(vocabulary_size-1)\n",
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
        "\n",
        "print (f\"Using vocabulary size {vocabulary_size}.\" )\n",
        "print (f\"The least frequent word in our vocabulary is '{vocab[-1][0]}' and appeared {vocab[-1][1]} times.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CxBYzBs1o5N"
      },
      "source": [
        "### Exercise 2.1\n",
        "\n",
        "Code your own TF-IDF representation function and use it on this dataset. (Don't use code from libraries. Build your own function with Numpy/Pandas). Use the formular TFIDF = TF * (IDF+1). The effect of adding “1” to the idf in the equation above is that terms with zero idf, i.e., terms that occur in all documents in a training set, will not be entirely ignored. The term frequency is the raw count of a term in a document. The inverse document frequency is the natural logarithm of the inverse fraction of the documents that contain the word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LAQX0zw11o5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107474dd-cfa4-4988-a6b7-31601d8ce844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is this implementation correct?\n",
            "Answer: Yes\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "countvec = CountVectorizer()\n",
        "df = pd.DataFrame(countvec.fit_transform(data).toarray(),columns=countvec.get_feature_names_out())\n",
        "\n",
        "\n",
        "\n",
        "def tfidf(df):\n",
        "\n",
        "   IDF = np.log(df.index.size/(df!=0).sum())\n",
        "   return df.mul((IDF+1),axis=1)\n",
        "\n",
        "\n",
        "rep=  tfidf(df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check if your implementation is correct\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(norm=None, smooth_idf=False, use_idf=True)\n",
        "X_train = pd.DataFrame(vectorizer.fit_transform(data).toarray(), columns=countvec.get_feature_names_out())\n",
        "answer=['No','Yes']\n",
        "epsilon = 0.0001\n",
        "if rep is None:\n",
        "  print (f'Is this implementation correct?\\nAnswer: {answer[0]}')\n",
        "if rep is not None:\n",
        "  print (f'Is this implementation correct?\\nAnswer: {answer[1*np.all((X_train - rep) < epsilon)]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# an example of what to do with these similarities:\n",
        "\n",
        "\n",
        "# analysis with tf-idf\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similiarities = cosine_similarity(rep, rep) # measure of the similarity of the direction of two vectors"
      ],
      "metadata": {
        "id": "yvgshAez8XY2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.fill_diagonal(similiarities, 0)\n",
        "max_ind = np.unravel_index(similiarities.argmax(), similiarities.shape)\n",
        "similiarities[max_ind] # highest similarity of two documents"
      ],
      "metadata": {
        "id": "39RjLr9J8b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c01af6-9416-47e3-d540-79320208642f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31827847791180874"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}